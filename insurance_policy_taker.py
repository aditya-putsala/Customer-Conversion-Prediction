# -*- coding: utf-8 -*-
"""Insurance Policy Taker.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w5vmxa1Gcdz9_BB-hNHgsqSj3YcEnEDm

# Problem Statement

You are working for a new-age insurance company and employ multiple outreach plans to sell term insurance to your customers. Telephonic marketing campaigns still remain one of the most effective way to reach out to people however they incur a lot of cost. Hence, it is important to identify the customers that are most likely to convert beforehand so that they can be specifically targeted via call. We are given the historical marketing data of the insurance company and are required to build a ML model that will predict if a client will subscribe to the insurance.

### Importing Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go

"""### Loading Dataset

### Importing Data
"""

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Customer Conversion Prediction/Customer Conversion Prediction.csv')
df.head()

# Looking into the Dataset
df.info()

df.shape

df.describe()

"""# ***Data Cleaning***"""

# Checking for Null values
df.isna().sum()

"""There are no null values in the given dataset."""

# Exploring the Dataset
df.job.value_counts()

df.age.value_counts()

df.marital.value_counts()

df.education_qual.value_counts()

df.call_type.value_counts()

df.day.value_counts()

df.mon.value_counts()

df.dur.values

df.num_calls.value_counts()

df.prev_outcome.value_counts()

df.y.value_counts()

"""# ***Exploratory Data Analysis***"""

# Visualising the Data
sns.countplot(x=df['y'])
plt.title('Count of customer conversion.')
plt.xlabel('Customer conversion')
plt.ylabel('Count')
plt.show()

"""The following graph of target variable shows it is an unequal distribution.

## **age**
"""

px.histogram(x=df['age'])

sns.boxplot(x=df['age'])

"""Here we can see that there are a lot of outliers."""

below_20_0=0
below_20_1=0
age_30_0=0
age_30_1=0
age_40_0=0
age_40_1=0
age_50_0=0
age_50_1=0
age_60_0=0
age_60_1=0
above_60_0=0
above_60_1=0
for i in range(len(df)):
    if df.age.iloc[i]<=20:
      if df.y.iloc[i]=='no':
        below_20_0+=1
      else:
        below_20_1+=1
    elif df.age.iloc[i]>20 and df.age.iloc[i]<=30:
      if df.y.iloc[i]=='no':
        age_30_0+=1
      else:
        age_30_1+=1
    elif df.age.iloc[i]>30 and df.age.iloc[i]<=40:
      if df.y.iloc[i]=='no':
        age_40_0+=1
      else:
        age_40_1+=1
    elif df.age.iloc[i]>40 and df.age.iloc[i]<=50:
      if df.y.iloc[i]=='no':
        age_50_0+=1
      else:
        age_50_1+=1
    elif df.age.iloc[i]>50 and df.age.iloc[i]<=60:
      if df.y.iloc[i]=='no':
        age_60_0+=1
      else:
        age_60_1+=1
    else:
      if df.y.iloc[i]=='no':
        above_60_0+=1
      else:
        above_60_1+=1
data={'no':[below_20_0,age_30_0,age_40_0,age_50_0,age_60_0,above_60_0],
      'yes':[below_20_1,age_30_1,age_40_1,age_50_1,age_60_1,above_60_1]}
age_cons = pd.DataFrame(data=data,index=['below_20','age_30','age_40','age_50','age_60','above_60'])
age_cons

fig = go.Figure()
fig.add_trace(go.Bar(x=age_cons.index, y=age_cons.yes,
                base=[0],marker_color='blue',
                name='yes'
                ))
fig.add_trace(go.Bar(x=age_cons.index, y=age_cons.no,
                base=[-64,-5821,-15875,-10220,-7256,-686],marker_color='yellow',
                name='no'))

fig.show()

total_below_20=below_20_0+below_20_1
below_20_0p=(below_20_0/total_below_20)*100
below_20_1p=100-below_20_0

total_age_30=age_30_0+age_30_1
age_30_0p=(age_30_0/total_age_30)*100
age_30_1p=100-age_30_0p

total_age_40=age_40_0+age_40_1
age_40_0p=(age_40_0/total_age_40)*100
age_40_1p=100-age_40_0p

total_age_50=age_50_0+age_50_1
age_50_0p=(age_50_0/total_age_50)*100
age_50_1p=100-age_50_0p

total_age_60=age_60_0+age_60_1
age_60_0p=(age_60_0/total_age_60)*100
age_60_1p=100-age_60_0p

total_above_60=above_60_0+above_60_1
above_60_0p=(above_60_0/total_above_60)*100
above_60_1p=100-above_60_0p

data={'no':[below_20_0p,age_30_0p,age_40_0p,age_50_0p,age_60_0p,above_60_0p],
      'yes':[below_20_1p,age_30_1p,age_40_1p,age_50_1p,age_60_1p,above_60_1p]}
age_cons_p = pd.DataFrame(data=data,index=['below_20p','age_30p','age_40p','age_50p','age_60p','above_60p'])
age_cons_p

fig = go.Figure()
fig.add_trace(go.Bar(x=age_cons_p.index, y=age_cons_p.yes,
                base=0,marker_color='blue',
                name='yes'
                ))
fig.add_trace(go.Bar(x=age_cons_p.index, y=age_cons_p.no,
                base=[-65.98,-83.97,-89.8,-90.94,-89.95,-57.8],marker_color='yellow',
                name='no'))

fig.show()

"""From the above graph we can say two most insurance buying groups are 

1) above 60 aged people
2) below 20 aged people

People likely to get insurance decreases from 20 till age 50 and we can see a sudden rise after 50.

# **job**
"""

plt.figure(figsize=(15,7))
sns.countplot(x=df['job'],hue=df['y'],data=df)

# Management Percentage
mgt = (df[(df['job']=='management')]['y']).value_counts()
mgt_per_yes = ((mgt['yes'] / (mgt['yes'] + mgt['no']))*100).round(2)
mgt_per_no = 100 - mgt_per_yes

# Technician Percentage
tech = (df[(df['job']=='technician')]['y']).value_counts()
tech_per_yes = ((tech['yes'] / (tech['yes'] + tech['no']))*100).round(2)
tech_per_no = 100 - (tech_per_yes)

# Entrepreneur Percentage
entr = (df[(df['job']=='entrepreneur')]['y']).value_counts()
entr_per_yes = ((entr['yes'] / (entr['yes'] + entr['no']))*100).round(2)
entr_per_no = 100 - entr_per_yes

# Blue-Collar Percentage
blue_col = (df[(df['job']=='blue-collar')]['y']).value_counts()
blue_col_per_yes = ((blue_col['yes'] / (blue_col['yes'] + blue_col['no']))*100).round(2)
blue_col_per_no = 100 - blue_col_per_yes

# Unknown Percentage
unko = (df[(df['job']=='unknown')]['y']).value_counts()
unko_per_yes = ((unko['yes'] / (unko['yes'] + unko['no']))*100).round(2)
unko_per_no = 100 - unko_per_yes

# Retired Percentage
rtd = (df[(df['job']=='retired')]['y']).value_counts()
rtd_per_yes = ((rtd['yes'] / (rtd['yes'] + rtd['no']))*100).round(2)
rtd_per_no = 100 - rtd_per_yes

# Admin Percentage
adm = (df[(df['job']=='admin.')]['y']).value_counts()
adm_per_yes = ((adm['yes'] / (adm['yes'] + adm['no']))*100).round(2)
adm_per_no = 100 - adm_per_yes

# Services Percentage
serv = (df[(df['job']=='services')]['y']).value_counts()
serv_per_yes = ((serv['yes'] / (serv['yes'] + serv['no']))*100).round(2)
serv_per_no = 100 - serv_per_yes

# Self-Employed Percentage
self_emp = (df[(df['job']=='self-employed')]['y']).value_counts()
self_emp_per_yes = ((self_emp['yes'] / (self_emp['yes'] + self_emp['no']))*100).round(2)
self_emp_per_no = 100 - self_emp_per_yes

# UnEmployed Percentage
unemp = (df[(df['job']=='unemployed')]['y']).value_counts()
unemp_per_yes = ((unemp['yes'] / (unemp['yes'] + unemp['no']))*100).round(2)
unemp_per_no = 100 - unemp_per_yes

# Housemaid Percentage
maid = (df[(df['job']=='housemaid')]['y']).value_counts()
maid_per_yes = ((maid['yes'] / (maid['yes'] + maid['no']))*100).round(2)
maid_per_no = 100 - maid_per_yes

# Student Percentage
stu = (df[(df['job']=='student')]['y']).value_counts()
stu_per_yes = ((stu['yes'] / (stu['yes'] + stu['no']))*100).round(2)
stu_per_no = 100 - stu_per_yes

data = {'no': [mgt_per_no,tech_per_no,entr_per_no,blue_col_per_no,unko_per_no,rtd_per_no,adm_per_no,serv_per_no,self_emp_per_no,unemp_per_no,maid_per_no,stu_per_no],
        'yes': [mgt_per_yes,tech_per_yes,entr_per_yes,blue_col_per_yes,unko_per_yes,rtd_per_yes,adm_per_yes,serv_per_yes,self_emp_per_yes,unemp_per_yes,maid_per_yes,stu_per_yes]}
job_per = pd.DataFrame(data=data,index=['management','technician','entrepreneur','blue-collar','unknown','retired','admin','services','self-employed','unemployed','housemaid','student'])
job_per



fig = go.Figure()
fig.add_trace(go.Bar(x=job_per.index, y=job_per.yes,
                base=[0],marker_color='blue',
                name='yes'
                ))
fig.add_trace(go.Bar(x=job_per.index, y=job_per.no,
                base=[-86.24,-88.94,-91.73,-92.73,-88.19,-77.21,-87.80,-91.12,-88.16,-84.50,-91.21,-71.32],marker_color='yellow',
                name='no'))

fig.show()

"""The graph shows Students and Retired persons are more likely to opt for an insurance.

# **marital**
"""

sns.countplot(x=df['marital'],hue=df['y'],data=df)

single_0=0
single_1=0
married_0=0
married_1=0
divorced_0=0
divorced_1=0
for i in range(len(df)):
  if df.marital.iloc[i]=='single':
    if df.y.iloc[i]=='no':
      single_0+=1
    else:
      single_1+=1
  elif df.marital.iloc[i]=='married':
    if df.y.iloc[i]=='no':
      married_0+=1
    else:
      married_1+=1
  else:
    if df.marital.iloc[i]=='no':
      divorced_0+=1
    else:
      divorced_1+=1
data={'no':[single_0,married_0,divorced_0],
      'yes':[single_1,married_1,divorced_1]}
marital_cons=pd.DataFrame(data=data,index=['single','married','divorced'])
marital_cons

fig = go.Figure()
fig.add_trace(go.Bar(x=marital_cons.index, y=marital_cons.yes,
                base=[0],marker_color='blue',
                name='yes'
                ))
fig.add_trace(go.Bar(x=marital_cons.index, y=marital_cons.no,
                base=[-10878,-24459,0],marker_color='yellow',
                name='no'))

fig.show()

total_single=single_0+single_1
single_0p=(single_0/total_single)*100
single_1p=100-single_0p

total_married=married_0+married_1
married_0p=(married_0/total_married)*100
married_1p=100-married_0p

total_divorced=divorced_0+divorced_1
divorced_0p=(divorced_0/total_divorced)*100
divorced_1p=100-divorced_0p

data={'no':[single_0p,married_0p,divorced_0p],
      'yes':[single_1p,married_1p,divorced_1p]}
marital_cons_per=pd.DataFrame(data=data,index=['single','married','divorced'])
marital_cons_per

fig = go.Figure()
fig.add_trace(go.Bar(x=marital_cons_per.index, y=marital_cons_per.yes,
                base=[0],marker_color='blue',
                name='yes'
                ))
fig.add_trace(go.Bar(x=marital_cons_per.index, y=marital_cons_per.no,
                base=[-85.1,-89.9,0],marker_color='yellow',
                name='no'))

fig.show()

"""From the above graph we can say,

1) People from divorced group getting an insurance is very high

2)Many were getting insured after a married life.

# **edu_qual**
"""

sns.countplot(x=df['y'],hue=df['education_qual'],data=df)

primary_0=0
primary_1=0
secondary_0=0
secondary_1=0
tertiary_0=0
tertiary_1=0
unknown_0=0
unknown_1=0
for i in range(len(df)):
  if df.education_qual.iloc[i]=='primary':
    if df.y.iloc[i]=='no':
      primary_0+=1
    else:
      primary_1+=1
  elif df.education_qual.iloc[i]=='secondary':
    if df.y.iloc[i]=='no':
      secondary_0+=1
    else:
      secondary_1+=1
  elif df.education_qual.iloc[i]=='tertiary':
    if df.y.iloc[i]=='no':
      tertiary_0+=1
    else:
      tertiary_1+=1
  else:
    if df.y.iloc[i]=='no':
      unknown_0+=1
    else:
      unknown_1+=1
data={'no':[primary_0,secondary_0,tertiary_0,unknown_0],
      'yes':[primary_1,secondary_1,tertiary_1,unknown_1]}
edu_cons=pd.DataFrame(data=data,index=['primary','secondary','tertiary','unknown'])
edu_cons

total_primary=primary_0+primary_1
primary_0p=(primary_0/total_primary)*100
primary_1p=100-primary_0p

total_secondary=secondary_0+secondary_1
secondary_0p=(secondary_0/total_secondary)*100
secondary_1p=100-secondary_0p

total_tertiary=tertiary_0+tertiary_1
tertiary_0p=(tertiary_0/total_tertiary)*100
tertiary_1p=100-tertiary_0p

total_unknown=unknown_0+unknown_1
unknown_0p=(unknown_0/total_unknown)*100
unknown_1p=100-unknown_0p

data={'no':[primary_0p,secondary_0p,tertiary_0p,unknown_0p],
      'yes':[primary_1p,secondary_1p,tertiary_1p,unknown_1p]}
edu_cons_per=pd.DataFrame(data=data,index=["primary","secondary","tertiary","unknown"])
edu_cons_per

fig = go.Figure()
fig.add_trace(go.Bar(x=edu_cons_per.index, y=edu_cons_per.yes,
                base=[0],marker_color='blue',
                name='yes'
                ))
fig.add_trace(go.Bar(x=edu_cons_per.index, y=edu_cons_per.no,
                base=[-91.4,-89.5,-85,-86.5],marker_color='yellow',
                name='no'))

fig.show()

"""The above graph can be interepreted as with increase in Educational qualification the person opting for an insurance increases.

1)Higher educated people are going to be a good choice for the company to make a call.
"""



"""# **call_type**"""

sns.countplot(x=df['call_type'],hue=df['y'])

unknown_0=0
unknown_1=0
cellular_0=0
cellular_1=0
telephone_0=0
telephone_1=0
for i in range(len(df)):
  if df.call_type.iloc[i]=='unknown':
    if df.y.iloc[i]=='no':
      unknown_0+=1
    else:
      unknown_1+=1
  elif df.call_type.iloc[i]=='cellular':
    if df.y.iloc[i]=='no':
      cellular_0+=1
    else:
      cellular_1+=1
  else:
    if df.y.iloc[i]=='no':
      telephone_0+=1
    else:
      telephone_1+=1
data={'no':[unknown_0,cellular_0,telephone_0],
      'yes':[unknown_1,cellular_1,telephone_1]}
call_type_cons=pd.DataFrame(data=data,index=['unknown','cellular','telephone'])
call_type_cons

fig = go.Figure()
fig.add_trace(go.Bar(x=call_type_cons.index, y=call_type_cons.yes,
                base=[0],marker_color='blue',
                name='yes'
                ))
fig.add_trace(go.Bar(x=call_type_cons.index, y=call_type_cons.no,
                base=[-12490,-24916,-2516],marker_color='yellow',
                name='no'))

fig.show()

total_unknown=unknown_0+unknown_1
unknown_0p=(unknown_0/total_unknown)*100
unknown_1p=100-unknown_0p

total_cellular=cellular_0+cellular_1
cellular_0p=(cellular_0/total_cellular)*100
cellular_1p=100-cellular_0p

total_telephone=telephone_0+telephone_1
telephone_0p=(telephone_0/total_telephone)*100
telephone_1p=100-telephone_0p

data={'no':[unknown_0p,cellular_0p,telephone_0p],
      'yes':[unknown_1p,cellular_1p,telephone_1p]}
call_cons_per=pd.DataFrame(data=data,index=['unknown','cellular','telephone'])
call_cons_per

fig = go.Figure()
fig.add_trace(go.Bar(x=call_cons_per.index, y=call_cons_per.yes,
                base=[0],marker_color='blue',
                name='yes'
                ))
fig.add_trace(go.Bar(x=call_cons_per.index, y=call_cons_per.no,
                base=[-96,-85.1,-86.6],marker_color='yellow',
                name='no'))

fig.show()

"""This graph shows the Insurance company employees are making good use of Cellular phones to get a customer.

## **day**
"""

week_1_0=0
week_1_1=0
week_2_0=0
week_2_1=0
week_3_0=0
week_3_1=0
week_4_0=0
week_4_1=0
for i in range(len(df)):
  if df.day.iloc[i]<8:
    if df.y.iloc[i]=='no':
      week_1_0+=1
    else:
      week_1_1+=1
  elif df.day.iloc[i]>=8 and df.day.iloc[i]<15:
    if df.y.iloc[i]=='no':
      week_2_0+=1
    else:
      week_2_1+=1
  elif df.day.iloc[i]>=15 and df.day.iloc[i]<22:
    if df.y.iloc[i]=='no':
      week_3_0+=1
    else:
      week_3_1+=1
  else:
    if df.y.iloc[i]=='no':
      week_4_0+=1
    else:
      week_4_1+=1
data={'no':[week_1_0,week_2_0,week_3_0,week_4_0],
      'yes':[week_1_1,week_2_1,week_3_1,week_4_1]
      }
day_cons=pd.DataFrame(data=data,index=['week_1','week_2','week_3','week_4'])
day_cons

week_1_total = week_1_0 + week_1_1

week_1_0_per = (week_1_0/week_1_total)*100

week_1_1_per = 100-week_1_0_per

fig = go.Figure()
fig.add_trace(go.Bar(x=day_cons.index, y=day_cons.no,
                base=0,marker_color='lightslategrey',
                name='no'
                ))
fig.add_trace(go.Bar(x=day_cons.index, y=day_cons.yes,
                base=[0],marker_color='blue',
                name='yes'))

fig.show()

total_week_1=week_1_0+week_1_1
week_1_0p=(week_1_0/total_week_1)*100
week_1_1p=100-week_1_0p

total_week_2=week_2_0+week_2_1
week_2_0p=(week_2_0/total_week_2)*100
week_2_1p=100-week_2_0p

total_week_3=week_3_0+week_3_1
week_3_0p=(week_3_0/total_week_3)*100
week_3_1p=100-week_3_0p

total_week_4=week_4_0+week_4_1
week_4_0p=(week_4_0/total_week_4)*100
week_4_1p=100-week_4_0p


data={'no':[week_1_0p,week_2_0p,week_3_0p,week_4_0p],
      'yes':[week_1_1p,week_2_1p,week_3_1p,week_4_1p]}
week_cons_per=pd.DataFrame(data=data,index=['week_1','week_2','week_3','week_4'])
week_cons_per

fig = go.Figure()
fig.add_trace(go.Bar(x=week_cons_per.index, y=week_cons_per.yes,
                base=[0],marker_color='blue',
                name='yes'))
fig.add_trace(go.Bar(x=week_cons_per.index, y=week_cons_per.no,
                base=[-87.42,-86.9,-90.3,-88],marker_color='yellow',
                name='no'
                ))

fig.show()

"""The above graph shows, 

1)People are more likely to get an insurance in the second week of the month

2)The Third week is a bad week to ask customers for insurance

## **month**
"""

sns.countplot(x=df['mon'],hue=df['y'])

df['mon']=df['mon'].replace({'jan':0,'feb':1,'mar':2,'apr':3,'may':4,'jun':5,'jul':6,'aug':7,'sep':8,'oct':9,'nov':10,'dec':11})
first_quart_0 =0
first_quart_1 =0
second_quart_0 =0
second_quart_1 =0
third_quart_0 =0
third_quart_1 =0
fourth_quart_0 =0
fourth_quart_1 =0

for i in range(len(df)):
  if df.mon.iloc[i]<3:
    if df.y.iloc[i]=='no':
      first_quart_0+=1
    else:
      first_quart_1+=1
  elif df.mon.iloc[i]>=3 and df.mon.iloc[i]<6:
    if df.y.iloc[i]=='no':
      second_quart_0+=1
    else:
      second_quart_1+=1
  elif df.mon.iloc[i]>=6 and df.mon.iloc[i]<9:
    if df.y.iloc[i]=='no':
      third_quart_0+=1
    else:
      third_quart_1+=1
  else:
    if df.y.iloc[i]=='no':
      fourth_quart_0+=1
    else:
      fourth_quart_1+=1


data={'no':[first_quart_0,second_quart_0,third_quart_0,fourth_quart_0],
      'yes':[first_quart_1,second_quart_1,third_quart_1,fourth_quart_1]
      }
mon_cons=pd.DataFrame(data=data,index=['first_quart','second_quart','third_quart','fourth_quart'])
print(mon_cons)

import plotly.graph_objects as go
fig = go.Figure()
fig.add_trace(go.Bar(x=mon_cons.index, y=mon_cons.no,
                base=0,marker_color='red',
                name='no'))
fig.add_trace(go.Bar(x=mon_cons.index, y=mon_cons.yes,
                base=[-831,-2048,-1584,-826],marker_color='green',
                name='yes'
                ))
fig.show()

total_first_quart=first_quart_0+first_quart_1
first_quart_0p=(first_quart_0/total_first_quart)*100
first_quart_1p=100-first_quart_0p

total_second_quart=second_quart_0+second_quart_1
second_quart_0p=(second_quart_0/total_second_quart)*100
second_quart_1p=100-second_quart_0p


total_third_quart=third_quart_0+third_quart_1
third_quart_0p=(third_quart_0/total_third_quart)*100
third_quart_1p=100-third_quart_0p

total_fourth_quart=fourth_quart_0+fourth_quart_1
fourth_quart_0p=(fourth_quart_0/total_fourth_quart)*100
fourth_quart_1p=100-fourth_quart_0p

data={'no':[first_quart_0p,second_quart_0p,third_quart_0p,fourth_quart_0p],
      'yes':[first_quart_1p,second_quart_1p,third_quart_1p,fourth_quart_1p]}
mon_cons_per=pd.DataFrame(data=data,index=['first_quart','second_quart','third_quart','fourth_quart'])
mon_cons_per

fig = go.Figure()

fig.add_trace(go.Bar(x=mon_cons_per.index, y=mon_cons_per.yes,
                base=[0],marker_color='green',
                name='yes'
                ))
fig.add_trace(go.Bar(x=mon_cons_per.index, y=mon_cons_per.no,
                base=[-81.7,-90.7,-88.5,-83.2],marker_color='red',
                name='no'))

fig.show()

"""The month graph shows People are more likely to get an insurance in the beginning and the end of the year.

Here the second quarter is the worst time for a client to ask insurance from customers.
"""

num_calls_below_3_n = 0
num_calls_below_3_y = 0
num_calls_below_6_n = 0
num_calls_below_6_y = 0
num_calls_below_10_n = 0
num_calls_below_10_y = 0
num_calls_above_10_n = 0
num_calls_above_10_y = 0
for i in range(len(df)):
  if df.num_calls.iloc[i]<=3:
    if df.y.iloc[i] =="no":
      num_calls_below_3_n += 1
    else:
      num_calls_below_3_y += 1
  elif df.num_calls.iloc[i]<=6 and df.num_calls.iloc[i] > 3:
    if df.y.iloc[i] =="no":
      num_calls_below_6_n += 1
    else:
      num_calls_below_6_y += 1
  elif df.num_calls.iloc[i]<=10 and df.num_calls.iloc[i] > 5:
    if df.y.iloc[i] =="no":
      num_calls_below_10_n += 1
    else:
      num_calls_below_10_y += 1
  elif df.num_calls.iloc[i]>10 :
    if df.y.iloc[i] =="no":
      num_calls_above_10_n += 1
    else:
      num_calls_above_10_y += 1  
 
num_calls_data = {"no":[num_calls_below_3_n,num_calls_below_6_n,num_calls_below_10_n,num_calls_above_10_n],
                  "yes":[num_calls_below_3_y,num_calls_below_6_y,num_calls_below_10_y,num_calls_above_10_y]}   

num_calls_cons = pd.DataFrame(data = num_calls_data,index=['num_calls_below_3','num_calls_below_6','num_calls_below_10','num_calls_above_10'])
print(num_calls_cons)


fig = go.Figure()
fig.add_trace(go.Bar(x=num_calls_cons.index, y=num_calls_cons.no,
                base=0,marker_color='blue',
                name='no'))
fig.add_trace(go.Bar(x=num_calls_cons.index, y=num_calls_cons.yes,
                base=0,marker_color='green',
                name='yes'
                ))

fig.show()

num_calls_below_3 = num_calls_below_3_n + num_calls_below_3_y
num_calls_below_3_n_p=(num_calls_below_3_n/num_calls_below_3)*100
num_calls_below_3_y_p=100-num_calls_below_3_n_p

num_calls_below_6 = num_calls_below_6_n + num_calls_below_6_y
num_calls_below_6_n_p=(num_calls_below_6_n/num_calls_below_6)*100
num_calls_below_6_y_p=100-num_calls_below_6_n_p

num_calls_below_10 = num_calls_below_10_n + num_calls_below_10_y
num_calls_below_10_n_p=(num_calls_below_10_n/num_calls_below_10)*100
num_calls_below_10_y_p=100-num_calls_below_10_n_p

num_calls_above_10 = num_calls_above_10_n + num_calls_above_10_y
num_calls_above_10_n_p=(num_calls_above_10_n/num_calls_above_10)*100
num_calls_above_10_y_p=100-num_calls_above_10_n_p


data={'no':[num_calls_below_3_n_p,num_calls_below_6_n_p,num_calls_below_10_n_p,num_calls_above_10_n_p],
      'yes':[num_calls_below_3_y_p,num_calls_below_6_y_p,num_calls_below_10_y_p,num_calls_above_10_y_p,]}
num_calls_per=pd.DataFrame(data=data,index=['num_calls_below_3','num_calls_below_6','num_calls_below_10','num_calls_above_10'])
num_calls_per

fig = go.Figure()
fig.add_trace(go.Bar(x=num_calls_per.index, y=num_calls_per.yes,
                base=[0],marker_color='blue',
                name='yes'))
fig.add_trace(go.Bar(x=num_calls_per.index, y=num_calls_per.no,
                base=[-87.1,-91.7,-93.89,-96],marker_color='yellow',
                name='no'
                ))

fig.show()

"""From the graph we can know the potential of a customer getting insured with 3 calls itself.

Any calls more than 10 times is not showing us the desirable output.
"""

duration_below_250_n = 0
duration_below_250_y = 0
duration_below_500_n = 0
duration_below_500_y = 0
duration_below_750_n = 0
duration_below_750_y = 0
duration_below_1000_n = 0
duration_below_1000_y = 0
duration_above_1000_n = 0
duration_above_1000_y = 0

for i in range(len(df)):
    if df.dur.iloc[i]<=250:
      if df.y.iloc[i]=='no':
        duration_below_250_n+=1
      else:
        duration_below_250_y+=1
    elif df.dur.iloc[i]>250 and df.dur.iloc[i]<=500:
      if df.y.iloc[i]=='no':
        duration_below_500_n+=1
      else:
        duration_below_500_y+=1
    elif df.dur.iloc[i]>500 and df.dur.iloc[i]<=750:
      if df.y.iloc[i]=='no':
        duration_below_750_n+=1
      else:
        duration_below_750_y+=1
    elif df.dur.iloc[i]>750 and df.dur.iloc[i]<=1000:
      if df.y.iloc[i]=='no':
        duration_below_1000_n+=1
      else:
        duration_below_1000_y+=1
    elif df.dur.iloc[i]>1000:
      if df.y.iloc[i]=='no':
        duration_above_1000_n+=1
      else:
        duration_above_1000_y+=1

duration_data={'no':[duration_below_250_n,duration_below_500_n,duration_below_750_n,duration_below_1000_n,duration_above_1000_n],
               'yes':[duration_below_250_y,duration_below_500_y,duration_below_750_y,duration_below_1000_y,duration_above_1000_y]}

duration_cons = pd.DataFrame(data=duration_data,index=['duration below 250 seconds','duration below 500 seconds','duration below 750 seconds','duration below 1000 seconds','duration above 1000 seconds'])
print(duration_cons)


fig = go.Figure()
fig.add_trace(go.Bar(x=duration_cons.index, y=duration_cons.no,
                base=[-28154,-8674,-2065,-603,-426],marker_color='blue',
                name='no'))
fig.add_trace(go.Bar(x=duration_cons.index, y=duration_cons.yes,
                base=0,marker_color='green',
                name='yes'
                ))

fig.show()

duration_below_250 = duration_below_250_n + duration_below_250_y
duration_below_250_n_p=(duration_below_250_n/duration_below_250)*100
duration_below_250_y_p=100-duration_below_250_n_p

duration_below_500 = duration_below_500_n + duration_below_500_y
duration_below_500_n_p=(duration_below_500_n/duration_below_500)*100
duration_below_500_y_p=100-duration_below_500_n_p

duration_below_750 = duration_below_750_n + duration_below_750_y
duration_below_750_n_p=(duration_below_750_n/duration_below_750)*100
duration_below_750_y_p=100-duration_below_750_n_p

duration_below_1000 = duration_below_1000_n + duration_below_1000_y
duration_below_1000_n_p=(duration_below_1000_n/duration_below_1000)*100
duration_below_1000_y_p=100-duration_below_1000_n_p

duration_above_1000 = duration_above_1000_n + duration_above_1000_y
duration_above_1000_n_p=(duration_above_1000_n/duration_above_1000)*100
duration_above_1000_y_p=100-duration_above_1000_n_p


data={'no':[duration_below_250_n_p,duration_below_500_n_p,duration_below_750_n_p,duration_below_1000_n_p,duration_above_1000_n_p],
      'yes':[duration_below_250_y_p,duration_below_500_y_p,duration_below_750_y_p,duration_below_1000_y_p,duration_above_1000_y_p]}
duration_data_per=pd.DataFrame(data=data,index=['duration below 250 seconds','duration below 500 seconds','duration below 750 seconds','duration below 1000 seconds','duration above 1000 seconds'])
print(duration_data_per)


fig = go.Figure()
fig.add_trace(go.Bar(x=duration_data_per.index, y=duration_data_per.yes,
                base=[0],marker_color='blue',
                name='yes'))
fig.add_trace(go.Bar(x=duration_data_per.index, y=duration_data_per.no,
                base=[-95.32,-84.16,-66.42,-50.08,-40.26],marker_color='yellow',
                name='no'
                ))

fig.show()

"""A customer like;y to get an insurance increases gradually with duration of call.

This may be due to trust issues.
"""

df['prev_outcome']=df['prev_outcome'].replace({"other":"unknown"})

df['prev_outcome'].unique()

# Applying One hot encoding to job column

one_hot = pd.get_dummies(df['job'])

df = df.drop('job',axis=1)

df = df.join(one_hot)
df.head()

# Mapping values to marital status
df['marital'] = df['marital'].map({'single':0,'married':1,'divorced':2}).astype(int)
df.head()

# Mapping values to Educational Qualification
df['education_qual'] = df['education_qual'].map({'unknown':0,'primary':1,'secondary':2,'tertiary':3}).astype(int)
df.head()

# Mapping values to Call type
df['call_type'] = df['call_type'].map({'telephone':0,'unknown':1,'cellular':2}).astype(int)
df.head()

# Mapping values to Previous Outcomes
df['prev_outcome'] = df['prev_outcome'].map({'success':0,'failure':1,'unknown':2}).astype(int)
df.head()

df['y']=df['y'].replace({'yes':1,'no':0})

df.y.unique()

df.head(5)

"""# **MODELLING**"""

x=df.drop('y',axis=1)
y=df.y

"""The training dataset and test dataset must be similar, usually have the same predictors or variables. They differ on the observations and specific values in the variables. If you fit the model on the training dataset, then you implicitly minimize error or find correct responses. The fitted model provides a good prediction on the training dataset. Then you test the model on the test dataset. If the model predicts good also on the test dataset, you have more confidence. You have more confidence since the test dataset is similar to the training dataset, but not the same nor seen by the model. It means the model transfers prediction or learning in real sense.

So,by splitting dataset into training and testing subset, we can efficiently measure our trained model since it never sees testing data before.Thus it's possible to prevent overfitting.

I am just splitting dataset into 20% of test data and remaining 80% will used for training the model.
"""

# Splitting the Data
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)

# Scaling the Data
from sklearn.preprocessing import StandardScaler 
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train) 
X_test_scaled = scaler.transform(X_test)

"""## **KNN**"""

# Fitting KNN Classifier to Training set
from sklearn.neighbors import KNeighborsClassifier
model = KNeighborsClassifier(n_neighbors=6)
model.fit(X_train,y_train)

y_pred_knn = model.predict(X_test)
y_pred_knn

from sklearn.metrics import roc_curve,roc_auc_score

y_score1 = model.predict_proba(X_test)[:,1]
false_positive_rate_knn, true_positive_rate_knn, threshold1 = roc_curve(y_test, y_score1)
print('AUROC_score : ', roc_auc_score(y_test, y_score1))

from sklearn.metrics import confusion_matrix
cm =confusion_matrix(y_test,y_pred_knn)
sns.heatmap(cm,annot=True)
cm

"""## **DecissionTree**"""

from sklearn.model_selection import train_test_split
X = df.drop(['y'],axis = 1)
y = df['y']
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.22 ,random_state = 0)

from sklearn.preprocessing import StandardScaler
 standardisation = StandardScaler()
 X_after_standardise =  standardisation.fit_transform(X_train)
 print(X_after_standardise)

from sklearn import tree
model  = tree.DecisionTreeClassifier()
model.fit(X_train,y_train)

y_pred = model.predict(X_test)
y_pred

from sklearn.metrics import roc_auc_score,f1_score,accuracy_score
AUROC = roc_auc_score(y_test,y_pred)
print("AUROC SCORE:",AUROC)
accuracy = accuracy_score(y_test,y_pred)
print("accuracy: ",accuracy)

from sklearn.metrics import confusion_matrix
cm =confusion_matrix(y_test,y_pred)
sns.heatmap(cm,annot=True)
cm

from sklearn.metrics import roc_curve
y_score1 = model.predict_proba(X_test)[:,1]
false_positive_rate, true_positive_rate, thershold1 = roc_curve(y_test,y_score1)
plt.subplots(1,figsize=(10,10))
plt.title("Receiver Operating Characeristic")
plt.plot(false_positive_rate, true_positive_rate)
plt.plot([0,1],ls="--")
plt.plot([0,0],[1,0],c=".7"),plt.plot([1,1],c=".7")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

"""## **RandomForestClassifier**"""

from sklearn.model_selection import train_test_split
X =df.drop(['y'],axis=1)
y =df['y']
X_train,X_test,y_train,y_test =train_test_split(X,y, test_size= 0.33,random_state =0)

from sklearn.preprocessing import StandardScaler
standardisation =StandardScaler()
X_after_standardise=standardisation.fit_transform(X_train)
print(X_after_standardise)

from sklearn.ensemble import RandomForestClassifier
rfc =RandomForestClassifier(n_estimators=100,criterion='entropy')
rfc.fit(X_train,y_train)

y_pred =rfc.predict(X_test)
y_pred

from sklearn.metrics import roc_auc_score,f1_score,accuracy_score
AUROC =roc_auc_score(y_test,y_pred)
F1_score =f1_score(y_test,y_pred)
print("AUROC score:",AUROC)
accuracy = accuracy_score(y_test,y_pred)
print("accuracy: ",accuracy)

from sklearn.metrics import confusion_matrix
cm =confusion_matrix(y_test,y_pred)
sns.heatmap(cm,annot=True)
cm

from sklearn.metrics import roc_curve
y_score1 = rfc.predict_proba(X_test)[:,1] 
false_positive_rate, true_positive_rate, threshold1 = roc_curve(y_test, y_score1) 
plt.subplots(1, figsize=(10,10)) 
plt.title('Receiver Operating Characteristic -Random forest classifier')
plt.plot(false_positive_rate, true_positive_rate) 
plt.plot([0, 1], ls="--")
plt.plot([0, 0], [1, 0] , c=".7"), plt.plot([1, 1] , c=".7") 
plt.ylabel('True Positive Rate') 
plt.xlabel('False Positive Rate') 
plt.show()

"""## **XGB**"""

import xgboost as xgb
model = xgb.XGBClassifier(learning_rate = 0.5, n_estimators =100 , verbosity = 0,random_state=50)
model.fit(X_train, y_train)
y_pred=model.predict(X_test)
y_pred

from sklearn.metrics import roc_auc_score,f1_score,accuracy_score
AUROC =roc_auc_score(y_test,y_pred)
print("AUROC score:",AUROC)
accuracy = accuracy_score(y_test,y_pred)
print("accuracy: ",accuracy)

from sklearn.metrics import confusion_matrix
cm =confusion_matrix(y_test,y_pred)
sns.heatmap(cm,annot=True)
cm

from sklearn.metrics import roc_curve
y_score1 = rfc.predict_proba(X_test)[:,1] 
false_positive_rate, true_positive_rate, threshold1 = roc_curve(y_test, y_score1) 
plt.subplots(1, figsize=(10,10)) 
plt.title('Receiver Operating Characteristic -XGB classifier')
plt.plot(false_positive_rate, true_positive_rate) 
plt.plot([0, 1], ls="--")
plt.plot([0, 0], [1, 0] , c=".7"), plt.plot([1, 1] , c=".7") 
plt.ylabel('True Positive Rate') 
plt.xlabel('False Positive Rate') 
plt.show()

"""## **Naive Bayes classifier**"""

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(X_train, y_train)
y_pred=gnb.predict(X_test)
y_pred

from sklearn.metrics import roc_auc_score,f1_score,accuracy_score
AUROC =roc_auc_score(y_test,y_pred)
print("AUROC score:",AUROC)
accuracy = accuracy_score(y_test,y_pred)
print("accuracy: ",accuracy)

from sklearn.metrics import confusion_matrix
cm =confusion_matrix(y_test,y_pred)
sns.heatmap(cm,annot=True)
cm

from sklearn.metrics import roc_curve
y_score1 = rfc.predict_proba(X_test)[:,1] 
false_positive_rate, true_positive_rate, threshold1 = roc_curve(y_test, y_score1) 
plt.subplots(1, figsize=(10,10)) 
plt.title('Receiver Operating Characteristic -Naive Bayes classifier')
plt.plot(false_positive_rate, true_positive_rate) 
plt.plot([0, 1], ls="--")
plt.plot([0, 0], [1, 0] , c=".7"), plt.plot([1, 1] , c=".7") 
plt.ylabel('True Positive Rate') 
plt.xlabel('False Positive Rate') 
plt.show()

"""## **LogReg**

### Fitting Logistic Regression to Training set
"""

from sklearn.linear_model import LogisticRegression
log = LogisticRegression(max_iter=1000)
log.fit(X_train, y_train)

"""### Prediction of Logistic Regression Model"""

y_pred  =  log.predict(X_test)
y_pred

# Evaluating the Prediction
from sklearn.metrics import roc_curve, roc_auc_score
y_score1 = log.predict_proba(X_test)[:,1]
false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, y_score1)
print('AUROC_score : ', roc_auc_score(y_test, y_score1))
print("accuracy: ",accuracy_score(y_test,y_pred))

importance = log.coef_[0]
scores = []
for i,v in enumerate(importance):
  scores.append(("%.3f" % v))
scores
d = {}
for i,j in zip(scores,range(22)):
  d.update({j:i})

plt.bar([x for x in range(len(importance))], importance)
plt.show()

sorted_values = sorted(d.items(),key=lambda x:x[1],reverse=True)
print(sorted_values)

X_train.columns

print("Feature17: Student" ,sorted_values[0][1])
print("Feature3: Call_type" ,sorted_values[1][1])
print("Feature14: Retired" ,sorted_values[2][1])
print("Feature2: Marital" ,sorted_values[3][1])
print("Feature5: Month" ,sorted_values[4][1])
print("Feature0: Age" ,sorted_values[5][1])
print("Feature6: Duration of Calls" ,sorted_values[6][1])
print("Feature8: Previous Outcome" ,sorted_values[7][1])
print("Feature10: Blue-Collar" ,sorted_values[8][1])
print("Feature11: Entrepreneur" ,sorted_values[9][1])

# Plotting the ROC Curve
plt.subplots(1, figsize=(10,10))
plt.title('Receiver Operating Characteristic - Logistic_regression')
plt.plot(false_positive_rate1, true_positive_rate1)
plt.plot([0, 1], ls="--")
plt.plot([0, 0], [1, 0] , c=".7"), plt.plot([1, 1] , c=".7")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

from sklearn.metrics import confusion_matrix
conf_matrix = confusion_matrix(y_test,y_pred)
sns.heatmap(conf_matrix,annot=True)
conf_matrix

"""In this project I have analysed through the given data and used various machine learning models for prediction.

The problem statement given is Supervised Learning and of type Binary classification.

I have Evaluated our models with AUROC_Score and LogisticRegression was found to give highest score of 0.85.

The top 3 important feautures found from LogReg model are

        1)Student

        2)Retired persons

        3)Marital status

  Category Call_type also is holding highest importance in feauture selection, but I omiited that with a assumption that a Customer is not going to care about the means of calling.

The importance of Students and Retired person could be easily understood in the job vs target graphs.

The number of Singles getting an insurance is high from the marital status vs target graph.
"""



